{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9176ebf7",
   "metadata": {},
   "source": [
    "First model: random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0124e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    f1_score\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data = pd.read_csv(\"Dataset.csv\")  # change to your file name\n",
    "\n",
    "X = data.iloc[:, :30].copy()\n",
    "y_raw = data.iloc[:, 30].astype(str).str.strip()  \n",
    "\n",
    "def simplify_flare(label):\n",
    "    if label.startswith(\"C\"):\n",
    "        return \"C\"\n",
    "    elif label.startswith(\"M\"):\n",
    "        return \"M\"\n",
    "    elif label.startswith(\"X\"):\n",
    "        return \"X\"\n",
    "    elif label in {\"0\", \"0.0\"}:\n",
    "        return \"0\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "y_simplified = y_raw.apply(simplify_flare)\n",
    "\n",
    "print(\"=== Overall class counts (before split) ===\")\n",
    "overall_counts = y_simplified.value_counts().to_frame(\"count\")\n",
    "overall_counts[\"percent\"] = 100 * overall_counts[\"count\"] / len(y_simplified)\n",
    "print(overall_counts, \"\\n\")\n",
    "\n",
    "X = X.apply(pd.to_numeric, errors='coerce')\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(y_simplified)\n",
    "\n",
    "print(\"Encoded class mapping:\", dict(zip(encoder.classes_, encoder.transform(encoder.classes_))), \"\\n\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_imputed, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "def counts_pct(y, classes):\n",
    "    vc = pd.Series(y).value_counts().reindex(range(len(classes)), fill_value=0)\n",
    "    df = pd.DataFrame({\"label_id\": vc.index, \"count\": vc.values})\n",
    "    df[\"label\"] = df[\"label_id\"].map(dict(enumerate(classes)))\n",
    "    df[\"percent\"] = 100 * df[\"count\"] / df[\"count\"].sum()\n",
    "    return df[[\"label\", \"count\", \"percent\"]].set_index(\"label\")\n",
    "\n",
    "print(\"=== Train class distribution ===\")\n",
    "print(counts_pct(y_train, encoder.classes_), \"\\n\")\n",
    "\n",
    "print(\"=== Test class distribution ===\")\n",
    "print(counts_pct(y_test, encoder.classes_), \"\\n\")\n",
    "\n",
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy.fit(X_train, y_train)\n",
    "y_pred_dummy = dummy.predict(X_test)\n",
    "\n",
    "print(\"=== Majority-class baseline (DummyClassifier) ===\")\n",
    "print(\"Baseline accuracy:\", accuracy_score(y_test, y_pred_dummy))\n",
    "print(\"Baseline balanced accuracy:\", balanced_accuracy_score(y_test, y_pred_dummy))\n",
    "print(\"Baseline macro F1:\", f1_score(y_test, y_pred_dummy, average=\"macro\", zero_division=0), \"\\n\")\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    random_state=42,\n",
    "    class_weight='balanced_subsample',\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "macro_f1 = f1_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "weighted_f1 = f1_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "\n",
    "print(\"=== Random Forest performance (Test set) ===\")\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Balanced accuracy:\", bal_acc)\n",
    "print(\"Macro F1:\", macro_f1)\n",
    "print(\"Weighted F1:\", weighted_f1, \"\\n\")\n",
    "\n",
    "report = classification_report(\n",
    "    y_test, y_pred, target_names=encoder.classes_, zero_division=0, output_dict=True\n",
    ")\n",
    "per_class_recall = {label: report[label][\"recall\"] for label in encoder.classes_ if label in report}\n",
    "print(\"Per-class recall (focus on C/M/X vs 0):\")\n",
    "for lbl in encoder.classes_:\n",
    "    print(f\"  {lbl}: {per_class_recall.get(lbl, np.nan):.3f}\")\n",
    "print()\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=encoder.classes_, zero_division=0, digits=4))\n",
    "\n",
    "print(\"\\n=== Predicted class distribution on Test ===\")\n",
    "pred_df = counts_pct(y_pred, encoder.classes_)\n",
    "print(pred_df, \"\\n\")\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_norm = confusion_matrix(y_test, y_pred, normalize='true')  # row-normalized: recall per class\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\",\n",
    "            xticklabels=encoder.classes_, yticklabels=encoder.classes_, cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix (counts) - Flare Strength Categories\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "sns.heatmap(cm_norm, annot=True, fmt=\".2f\",\n",
    "            xticklabels=encoder.classes_, yticklabels=encoder.classes_, cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix (row-normalized) - Recall per Class\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Feature Importance (Top 10) ---\n",
    "importances = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "importances.head(10).plot(kind='bar', figsize=(8,5))\n",
    "plt.title(\"Top 10 Important Features\")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fa8869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    f1_score\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "def counts_pct(y, classes):\n",
    "    vc = pd.Series(y).value_counts().reindex(range(len(classes)), fill_value=0)\n",
    "    df = pd.DataFrame({\"label_id\": vc.index, \"count\": vc.values})\n",
    "    df[\"label\"] = df[\"label_id\"].map(dict(enumerate(classes)))\n",
    "    df[\"percent\"] = 100 * df[\"count\"] / df[\"count\"].sum()\n",
    "    return df[[\"label\", \"count\", \"percent\"]].set_index(\"label\")\n",
    "\n",
    "data = pd.read_csv(\"Dataset.csv\")  # change to your file name\n",
    "\n",
    "X = data.iloc[:, :30].copy()\n",
    "y_raw = data.iloc[:, 30].astype(str).str.strip()  # flare_strength column\n",
    "\n",
    "def simplify_flare(label):\n",
    "    if label.startswith(\"C\"):\n",
    "        return \"C\"\n",
    "    elif label.startswith(\"M\"):\n",
    "        return \"M\"\n",
    "    elif label.startswith(\"X\"):\n",
    "        return \"X\"\n",
    "    elif label in {\"0\", \"0.0\"}:\n",
    "        return \"0\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "y_simplified = y_raw.apply(simplify_flare)\n",
    "\n",
    "# Optionally drop 'Unknown' if any\n",
    "mask_known = y_simplified != \"Unknown\"\n",
    "X = X.loc[mask_known].reset_index(drop=True)\n",
    "y_simplified = y_simplified.loc[mask_known].reset_index(drop=True)\n",
    "\n",
    "print(\"=== Overall class counts (before split) ===\")\n",
    "overall_counts = y_simplified.value_counts().to_frame(\"count\")\n",
    "overall_counts[\"percent\"] = 100 * overall_counts[\"count\"] / len(y_simplified)\n",
    "print(overall_counts, \"\\n\")\n",
    "\n",
    "X = X.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(y_simplified)\n",
    "class_names = list(encoder.classes_)\n",
    "print(\"Encoded class mapping:\", dict(zip(class_names, encoder.transform(class_names))), \"\\n\")\n",
    "\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.20, random_state=RANDOM_STATE, stratify=y_encoded\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, random_state=RANDOM_STATE, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"=== Train class distribution ===\")\n",
    "print(counts_pct(y_train, class_names), \"\\n\")\n",
    "print(\"=== Validation class distribution ===\")\n",
    "print(counts_pct(y_val, class_names), \"\\n\")\n",
    "print(\"=== Test class distribution ===\")\n",
    "print(counts_pct(y_test, class_names), \"\\n\")\n",
    "\n",
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy.fit(X_train, y_train)\n",
    "\n",
    "for split_name, X_split, y_split in [\n",
    "    (\"Validation\", X_val, y_val),\n",
    "    (\"Test\", X_test, y_test),\n",
    "]:\n",
    "    y_pred_dummy = dummy.predict(X_split)\n",
    "    print(f\"=== Majority-class baseline (DummyClassifier) on {split_name} ===\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_split, y_pred_dummy))\n",
    "    print(\"Balanced accuracy:\", balanced_accuracy_score(y_split, y_pred_dummy))\n",
    "    print(\"Macro F1:\", f1_score(y_split, y_pred_dummy, average=\"macro\", zero_division=0), \"\\n\")\n",
    "\n",
    "svm = LinearSVC(\n",
    "    C=1.0,                    \n",
    "    class_weight='balanced',  \n",
    "    random_state=RANDOM_STATE,\n",
    "    max_iter=5000             \n",
    ")\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "    (\"svm\", svm)\n",
    "])\n",
    "\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = pipe.predict(X_train)\n",
    "print(\"=== SVM performance (Train set) ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
    "print(\"Balanced accuracy:\", balanced_accuracy_score(y_train, y_train_pred))\n",
    "print(\"Macro F1:\", f1_score(y_train, y_train_pred, average=\"macro\", zero_division=0), \"\\n\")\n",
    "\n",
    "y_val_pred = pipe.predict(X_val)\n",
    "print(\"=== SVM performance (Validation set) ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"Balanced accuracy:\", balanced_accuracy_score(y_val, y_val_pred))\n",
    "print(\"Macro F1:\", f1_score(y_val, y_val_pred, average=\"macro\", zero_division=0))\n",
    "print(\"Weighted F1:\", f1_score(y_val, y_val_pred, average=\"weighted\", zero_division=0), \"\\n\")\n",
    "\n",
    "print(\"Validation Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred, target_names=class_names, zero_division=0, digits=4))\n",
    "\n",
    "y_test_pred = pipe.predict(X_test)\n",
    "print(\"=== SVM performance (Test set) ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"Balanced accuracy:\", balanced_accuracy_score(y_test, y_test_pred))\n",
    "print(\"Macro F1:\", f1_score(y_test, y_test_pred, average=\"macro\", zero_division=0))\n",
    "print(\"Weighted F1:\", f1_score(y_test, y_test_pred, average=\"weighted\", zero_division=0), \"\\n\")\n",
    "\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=class_names, zero_division=0, digits=4))\n",
    "\n",
    "print(\"\\n=== Predicted class distribution on Validation ===\")\n",
    "print(counts_pct(y_val_pred, class_names), \"\\n\")\n",
    "print(\"=== Predicted class distribution on Test ===\")\n",
    "print(counts_pct(y_test_pred, class_names), \"\\n\")\n",
    "\n",
    "def plot_confusions(y_true, y_pred, classes, title_suffix):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_norm = confusion_matrix(y_true, y_pred, normalize='true')\n",
    "\n",
    "    plt.figure(figsize=(7,6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=classes, yticklabels=classes)\n",
    "    plt.title(f\"Confusion Matrix (counts) - {title_suffix}\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(7,6))\n",
    "    sns.heatmap(cm_norm, annot=True, fmt=\".2f\", cmap=\"Blues\",\n",
    "                xticklabels=classes, yticklabels=classes)\n",
    "    plt.title(f\"Confusion Matrix (row-normalized) - {title_suffix}\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_confusions(y_val, y_val_pred, class_names, \"Validation\")\n",
    "plot_confusions(y_test, y_test_pred, class_names, \"Test\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
